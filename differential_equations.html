<!DOCTYPE html>
<html>

<head>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://latex.now.sh/style.css">
    <link rel="stylesheet" href="style.css">
    <link rel="stylesheet" type="text/css" href="https://tikzjax.com/v1/fonts.css">
    <script src="https://tikzjax.com/v1/tikzjax.js"></script>
    <title>Differential Equations</title>
</head>

<body>
    <h1>Differential Equations</h1>

    <h4>What are differential equations?</h4>
    <p>A differential equation is any equation involving the derivatives of an unknown function, and its solution is the infinite family of functions that make the equation true. For example, given the differential equation\(\dots\)</p>
    \[ \frac{dy}{dx} = x^2 \]
    <p>\(\dots\)we can simply integrate both sides to find that\(\dots\)</p>
    \[ y = \frac{1}{3}x^3 + C \]
    <p>This represents the general family of solutions that solve the differential equation, however if we were asked to find a specific solution given an initial condition, we would then have to solve for the specific value of \(C\).</p>
    <p>A differential equation's order refers to the highest derivative that it contains. For example, the differential equation we looked at above is order 1, however the one below is order 2 since it contains a second-derivative.</p>
    \[ \frac{d^2y}{dx^2} = 2\cos(2x)\]
    <p>The general solution to a differential equation will always contain an equal number of arbitrary constants as its order. This makes sense if we consider that in order to solve a given equation, we would have to integrate a number of times equal to its order, and each integration would introduce a new constant.</p>

    <h4>What are slope fields?</h4>
    <p>While many differential equations can be solved simply through integration, others pose more of a challenge and some are even impossible to solve analytically. However, there are several techniques to <i>approximate</i> solutions. Slope fields are one such way of (albeit very roughly) approximating solutions to differential equations.</p>
    <p></p>
    <img src="vector_field.svg" alt="Vector field example" class="center">

    <p>The diagram above is a slope field where the tiny vectors indicate the slope of the family of solutions at each point. Given a slope field diagram, one can easily approximate the solution to a differential equation at any initial condition simply by tracing out the path of the arrows. To create your own slope field diagram, you first must have a rate of change equation which relates the rate of change of a function to the function's independent and dependent variables, as seen below.</p>
    \[\frac{dP}{dt}=f(t, P)\]
    <p>Then, for as many points as you wish, plug in values of \(t\) and \(P\) to find the slope of the solution at that particular point. Then simply draw an arrow with that slope at that point and repeat until you feel you have a sufficient number of points to approximate your solution.</p>

    <h4>What is Euler's method?</h4>
    <p>Euler's method is another, more analytic way of approximating differential equations. First, choose a step size, by which you'll repeatedly increment \(x\). Note that the closer your step size is to 0, the more accurate your approximation, but it will also be more tedious to compute. Suppose we are given the differential equation below and the accompanying inital condition.</p>
    \[ \frac{dy}{dx} = \frac{1}{3}xy \;\;\;\;\;\;\;\;\; y(0) = 1 \]
    <p>You would start by making a table with three columns: \(x\), \(y\), and \(\frac{dy}{dx}\). Use the given initial condition to fill in the first \(x\) and the first \(y\) value. The rest of the \(x\) column can then be completed by repeatedly incrementing the initial value of \(x\) by the step size. In the example table below, a step size of 0.5 is used.</p>
    <p>Next, find the first value of \(\frac{dy}{dx}\) by evaluating the right hand side of the given differential equation with the first \(x\) and \(y\). Then add the product of that \(\frac{dy}{dx}\) value and the step size to the current \(y\) value to find the next \(y\) and continue finding and adding such products until the table is complete.</p>
    \[ \begin{array} {|r|r|}\hline x & y & \frac{dy}{dx} \\ \hline 0.0 & 1.000 & 0.000 \\ \hline 0.5 & 1.000 & 0.167 \\ \hline 1.0 & 1.083 & 0.361 \\ \hline 1.5 & 1.264 & 0.632 \\ \hline 2.0 & 1.580 & 1.053 \\ \hline  \end{array} \]
    <p>With this table, we can estimate the values of the solution to the original differential equation at various \(x\) values, for example, we would predict its value at \(x\) = 2 to be 1.580. However, in reality, its true value is \(e^{2/3}\) or approximately 1.947. Notice that our estimation is quite far from the true value. This is because our step size, 0.5, is quite large. If our step size were 0.01, we would have arrived at a much closer estimation of 1.938, but it would have also taken 50 times as many steps to arrive at our answer. Thus, when using Euler's method it is critical to weigh the importance of accuracy against that of efficiency.</p>

    <h4>What are integrating factors?</h4>
    <p>Using an integrating factor allows us to manipulate the product rule in order to more easily solve a differential equation. This method is most effective when the equation is written in standard form, which is outlined below.</p>
    \[y' + p(t)y=g(t)\]
    <p>Often equations will not initially be in standard form, but can be achieved through simple algebraic manipulation. Once in standard form, multiply every term in the equation by \(\mu (t)\), called the integrating factor.</p>
    \[\mu (t)y' + \mu (t)p(t)y=\mu (t)g(t)\]
    <p>Now, the left hand side of the differential equation is now in the form of a derivative found with the product rule, which leads to equation below.</p>
    \[\mu '(t)=\mu (t)p(t)\]
    <p>We need only solve this new differential equation for \(\mu (t)\), and once it is known, we can rewrite the intial differential equation with the product rule.</p>
    \[\frac{d}{dt}\left[\mu (t)y\right]=\mu (t)g(t)\]
    <p>Finally, we can integrate both sides with respect to \(t\) and solve for \(y\) to find the below solution to the original differential equation.</p>
    \[y=\frac{1}{\mu (t)}\int\mu (t)g(t)dt\]

    <h4>What are exact differential equations?</h4>
    <p>From multivariable calculus, we know that if \(y\) is a function of \(x\dots\)</p>
    \[ \frac{d}{dx} f(x, y) = f_x(x, y) + f_y(x, y)y' \]
    <p>Thus if we are given a differential equation of the form\(\dots\)</p>
    \[ M(x,y)+N(x,y)y' = 0 \]
    <p>It is considered exact if it can be rewritten as the derivative of some multivariable potential function \(\psi(x, y)\). Thus, we can use Clairaut's Theorem, the equality of mixed partials, to show whether such a potential function exists, and by extension, whether this method will solve the differential equation.</p>
    \[ \frac{\partial M}{\partial y} = \frac{\partial N}{\partial x} \]
    <p>If the above equaiton is true, we know that there exists some potential function \(\psi(x, y)\) such that \(\psi_x=M\) and \(\psi_y=N\), thus we need only solve for \(\psi(x, y)\dots\)</p>
    \[ \psi (x, y) = \int M(x, y)\,dx = \int N(x, y)\,dy \]
    <p>\(\dots\)and finally solve the original differential equation restated as the derivative of the potential function, which can readily be solved through direct integration.</p>
    \[ \frac{d}{dx}\psi (x, y) = 0\]

    <h4>What is the existence and uniqueness theorem?</h4>
    <p>The existence and uniquess theorem can give conditions for when solutions are unique, and more broadly, whether solutions exist at all. Given an initial value problem\(\dots\)</p>
    \[ y' = f(t, y) \,\,\,\,\,\,\,\,\,\, y(t_0)=y_0\]
    <ul>
        <li>If \(f\) and \(\frac{\partial f}{\partial y}\) are continuous over some rectangular region \(\alpha \lt t \lt \beta, \delta \lt y \lt \gamma\) containing the point \((t_0, y_0)\), then there exists a <b>unique</b> solution around \(t_0\) over some subregion contained within \((\alpha, \beta)\).</li>
        <li>If \(f\) is continuous over some rectangular region \(\alpha \lt t \lt \beta, \delta \lt y \lt \gamma\), but \(\frac{\partial f}{\partial y}\) is not, then there exists a solution, but its uniqueness is not guaranteed.</li>
    </ul>

    <h4>What are characteristic equations?</h4>
    <p>Characteristic equations are polynomials found by substituting \(e^{rt}\) into linear homogeneous ODEs. For example, consider the differential equation below.</p>
    \[ ay''+by'+cy=0 \]
    <p>By substituting \(e^{rt}\) for \(y\) and differentiating it appropriately, the equation can be rewritten as\(\dots\)</p>
    \[e^{rt}(ar^2+br+c)=0\]
    <p>However, exponentials can never equal 0, therefore we arrive at the characteristic equation\(\dots\)</p>
    \[ar^2+br+c=0\]
    <p>Then, we need only find the roots of this characteristic equation to find the general solution to the ODE. However, there are four cases depending on the roots.</p>
    \[ \begin{array} {|r|r|}\hline \text{2 Real Roots} & r=r_1, r=r_2 & y=c_1e^{r_1t}+c_2e^{r_2t}\\ \hline \text{1 Real Root} & r=r_1 & y=c_1e^{r_1t}+c_2te^{r_1t}\\ \hline \text{2 Imaginary Roots} & r=\pm\beta i & y=c_1\cos{\beta t}+c_2\sin{\beta t}\\ \hline \text{2 Complex Roots} & r=\alpha\pm\beta i & y=e^{\alpha t}(c_1\cos{\beta t}+c_2\sin{\beta t})\\ \hline \end{array} \]

    <h4>What is Euler's formula?</h4>
    <p></p>
    \[ e^{i\theta} = \cos{\theta} + i\sin{\theta} \]

    <h4>What is the Wronskian?</h4>
    <p>The Wronskian is a special determinant used to show whether you can find a unique solution to an ODE. If \(W(t_0)=0\) for an initial value problem then a unique solution does not exist.</p>
    \[ W(t) = \begin{vmatrix} y_1(t) & y_2(t) \\ y_1'(t) & y_2'(t) \end{vmatrix} = y_1(t)y_2'(t) - y_2(t)y_1'(t)\]

    <h4>What is Abel's Theorem?</h4>
    <p></p>
    \[ W(t)=Ce^{-\int p(t) dt}\]

    <h4>What is variation of parameters?</h4>
    \[u_1(t)=-\int\frac{y_2g(t)}{W(y_1,y_2)}dt \text{ and } u_2(t)=\int\frac{y_1g(t)}{W(y_1,y_2)}dt\]
    \[Y_P(t)=y_1u_1+y_2u_2\]

    <h4>What is the Laplace Transform?</h4>
    <p></p>
    \[ \mathcal{L}\{f(t)\} = \int_0^\infty f(t)e^{-st}\,dt = F(s)\]

    <h4>What is the Heaviside Step Function?</h4>
    <p>The Heaviside step function is a function that evaluates to 0 when \(t \lt 0\) and 1 when \(t \gt 0\).</p>
    \[\theta(t)\]

    <h4>What is the Dirac Delta Function?</h4>
    <p>The Dirac delta function, notated by \(\delta\), is the derivative of the Heaviside step function. It evaluates to \(0\) everywhere except at \(t=0\), where it is undefined, such that the definite integral of the function containing \(0\) evaluates to \(1\).</p>
    \[ \frac{d}{dt} \theta(t) = \delta(t)\]
    \[\int_0^\infty\delta(t-c) dt = 1\]

    <h4>What is convolution?</h4>
    <p></p>
    \[ f(t) * g(t) = \int_0^t f(t-\tau)g(\tau) d\tau \]

    <h4>What are phase portraits?</h4>
    \[ \begin{array} {|r|r|}\hline
            \textbf{Eigenvalues} & \textbf{Origin Classification} & \textbf{Stability} \\ \hline
            \text{2 Real with Opposite Signs} & \text{Saddle} & \text{Unstable} \\ \hline
            \text{2 Real with Same Signs} & \text{Node} & \text{Stable if }\lambda \lt 0\\ \hline
            \text{2 Imaginary } (\pm\beta i) & \text{Center} & \text{Stable} \\ \hline
            \text{2 Complex } (\alpha\pm\beta i) & \text{Spiral} & \text{Unstable if }\alpha > 0 \\ \hline
        \end{array} \]

    <h4>?</h4>
    <p></p>
    \[ \]
</body>

<footer>
    <p>
        <script>
            var lastModified = new Date(document.lastModified);
            var date = lastModified.getMonth() + 1 + "/" + lastModified.getDate() + "/" + lastModified.getFullYear();
            document.write("Last modified on " + date + ".");
        </script>
        Please report any issues to <a href="mailto:elijah.m.kin@gmail.com">elijah.m.kin@gmail.com</a>!
    </p>
</footer>

</html>